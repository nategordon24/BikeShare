hist(sample_means, probability=TRUE, breaks=30,
main=paste("Sampling Distribution (n =", n, ")"),
xlab="Sample Mean", col="lightblue", border="black")
curve(dnorm(x, mean=0, sd=1/sqrt(n)), add=TRUE, col="red", lwd=2)  # Overlay normal density
Sys.sleep(1)  # Pause so you can see each plot before moving to the next
}
set.seed(123)  # For reproducibility
num_samples <- 10000  # Number of sample means to generate
n_values <- c(3, 15, 30)  # Different sample sizes
for (n in n_values) {
sample_means <- replicate(num_samples, mean(rnorm(n, mean=0, sd=1)))  # Compute sample means
hist(sample_means, probability=TRUE, breaks=30,
main=paste("Sampling Distribution (n =", n, ")"),
xlab="Sample Mean", col="lightblue", border="black")
curve(dnorm(x, mean=0, sd=1/sqrt(n)), add=TRUE, col="red", lwd=2)  # Overlay normal density
Sys.sleep(1)  # Pause so you can see each plot before moving to the next
}
set.seed(123)  # For reproducibility
num_samples <- 10000  # Number of sample means to generate
n_values <- c(3, 15, 30)  # Different sample sizes
for (n in n_values) {
sample_means <- replicate(num_samples, mean(rnorm(n, mean=0, sd=1)))  # Compute sample means
hist(sample_means, probability=TRUE, breaks=30,
main=paste("Sampling Distribution (n =", n, ")"),
xlab="Sample Mean", col="lightblue", border="black")
curve(dnorm(x, mean=0, sd=1/sqrt(n)), add=TRUE, col="red", lwd=2)  # Overlay normal density
Sys.sleep(1)  # Pause so you can see each plot before moving to the next
}
(126.3/sqrt(27))*1.96
364.3-47.64063
47.64063+364.3
pnorm(0.975)
qnorm(0.975)
# load any necessary packages here
library(tidyverse)
library(car)
#load data in
cancer <- read_table("
type gender age days
stomach 2 61  124
stomach 1 69   42
stomach 2 62   25
stomach 2 66   45
stomach 1 63  412
stomach 1 79   51
stomach 1 76 1112
stomach 1 54   46
stomach 1 62  103
stomach 1 46  146
stomach 1 57  340
stomach 2 59  396
bronchus 1 74   81
bronchus 1 74  461
bronchus 1 66   20
bronchus 1 52  450
bronchus 2 48  246
bronchus 2 64  166
bronchus 1 70   63
bronchus 1 77   64
bronchus 1 71  155
bronchus 1 39  151
bronchus 1 70  166
bronchus 1 70   37
bronchus 1 55  223
bronchus 1 74  138
bronchus 1 69   72
bronchus 1 73  245
colon 2 76  248
colon 2 58  377
colon 1 49  189
colon 1 69 1843
colon 2 70  180
colon 2 68  537
colon 1 50  519
colon 2 74  455
colon 1 66  406
colon 2 76  365
colon 2 56  942
colon 2 74  372
colon 1 58  163
colon 2 60  101
colon 1 77   20
colon 1 38  283
rectum 2 56  185
rectum 2 75  479
rectum 2 57  875
rectum 1 56  115
rectum 1 68  362
rectum 1 54  241
rectum 1 59 2175
bladder 1 93 4288
bladder 2 70 3658
bladder 2 77   51
bladder 2 72  278
bladder 1 44  548
kidney 2 71  205
kidney 2 63  538
kidney 2 51  203
kidney 1 53  296
kidney 1 57  870
kidney 1 73  331
kidney 1 69 1685
")
View(cancer)
View(cancer)
cancer |>
group_by(type) |>
summarize(mean(cancer))
View(cancer)
cancer |> cancer$days
cancer |>
group_by(type) |>
summarize(mean(cancer$days))
gg_plot(data=cancer, aes(x=type, y=days)) + geom_boxplot()
library(tidyverse)
gg_plot(data=cancer, aes(x=type, y=days)) + geom_boxplot()
library(tidyverse)
ggplot(data=cancer, aes(x=type, y=days)) + geom_boxplot()
#means
mean(cancer$days[cancer$type == "bladder"])
ggplot(data=cancer, aes(x=type, y=days)) + geom_boxplot()
var
cancer |>
group_by(type) |>
summarize(mean(days))
#compare means of different types
cancer |>
group_by(type) |>
summarize(sd(days))
#compare sd of different types
cancer |>
group_by(type) |>
summarize(sd(days))
library(tidyverse)
#boxplot of different
ggplot(data=cancer, aes(x=type, y=days)) + geom_boxplot()
#compare sd of different types
cancer |>
group_by(type) |>
summarize(sd(days))
library(tidyverse)
#boxplot of different
ggplot(data=cancer, aes(x=type, y=days)) + geom_histogram()
cancer$logd <- log(cancer$days)
cancer %>%
group_by(type) %>%
summarize(mean(logd))
t.test(mean_highsalt, mean_lowsalt, alternative = "two.sided", mu = "56.125", var.equal = TRUE, conf.level = 0.95)
mean_highsalt <- 74
mean_lowsalt <- 38.25
n_lowsalt <- 4
n_highsalt <-4
t.test(mean_highsalt, mean_lowsalt, alternative = "two.sided", mu = "56.125", var.equal = TRUE, conf.level = 0.95)
data <- read.csv(drug_consumption.data)
data <- read.csv(drug_consumption.data)
data <- read.csv(drug_consumption.data)
data <- read.csv(drug_consumption.data)
data <- read.csv(drug_consumption.data)
data <- read_csv(drug_consumption.data)
data <- read_csv(drug_consumption.data)
library(tidyverse)
data <- read.csv(drug_consumption.data)
rary(tidyverse)
library(tidyverse)
data <- read.csv(drug_consumption.data)
data <- read.csv(drug_consumption.data)
library(tidyverse)
data <- read.csv(drug_consumption.data)
library(tidyverse)
data <- read.csv(drug_consumption.data)
library(tidyverse)
data <- read.csv(drug_consumption.data)
library(tidyverse)
data <- read.csv(drug_consumption.data)
library(tidyverse)
data <- read.csv(drug_consumption.data)
data <- write.csv(drug_consumption.data)
library(tidyverse)
data <- write.csv(drug_consumption.data)
library(tidyverse)
data <- write.csv(drug_consumption.data)
library(tidyverse)
data <- write.csv(drug_consumption.data)
library(tidyverse)
data <- write.csv(drug_consumption.data)
library(tidyverse)
data <- write.csv(drug_consumption.data)
library(tidyverse)
data <- write.csv(drug_consumption.data)
library(tidyverse)
data <- read.csv(drug_consumption.csv)
library(tidyverse)
data <- read.csv(drug_consumption.csv)
library(tidyverse)
data <- read.csv(drug_consumption.csv)
library(tidyverse)
data <- read.csv(drug_consumption.csv)
library(tidyverse)
data <- read.csv(drug_consumption.csv)
library(tidyverse)
data <- read.csv(drug_consumption.csv)
library(tidyverse)
data <- read.csv(drug_consumption.csv)
library(tidyverse)
data <- read_csv(drug_consumption.csv)
library(tidyverse)
data <- read_csv(drug_consumption.csv)
qnorm(0.025)
qnorm(0.025,0.5,0.25/50)
qnorm(0.025,0.5,sqrt(0.25/50))
qnorm(0.975,0.5,sqrt(0.25/50))
pnorm(.361,0.1,sqrt(0.09/50))
1-pnorm(0.639,0.1,sqrt(0.09/50))
pnorm(.361,0.3,sqrt(0.21/50))
pnorm(.361,0.3,sqrt(0.21/50)) + (1-pnorm(0.639,0.3,sqrt(0.21/50)))
pnorm(.361,0.2,sqrt(0.16/50)) + (1-pnorm(0.639,0.2,sqrt(0.16/50)))
qnorm(0.025,0,1)
qnorm(0.025,0,sqrt(1/5))
qnorm(0.975,0,sqrt(1/5))
pnorm(7.66836)
pnorm(7.66)
pnorm(5)
(129.4538-128)/(2.1/sqrt(40))
pnorm(4.3783999)
1-pnorm(4.37)
(129.4538-128)/(2.1/sqrt(40))
pnorm(4.378399)
1-0.999994
1-0.999994)*10
(128.6-128)/(2.1/sqrt(40))
pnorm(1.807016)
pnorm(-1.645)
1-pnorm(4.378)
1-pnorm(4.378)*10
(1-pnorm(4.378))*10
((1-pnorm(4.378))*10)*10
pnorm(-0.4424885)
1-0.3290679
pnorm(-0.4424885)
1-pt(4.378,39)
10*(1-pt(4.378,39))
10*(1-pt(4.38,39))
1-pt(4.568,9)
qnorm(0.01)
qnorm(0.005)
qt(0.005,9)
qt(0.01,9)
pbinom(12,20,0.4)
pbinom(12,20,0.5)
pbinom(12,20,0.6)
pbinom(12,20,0.7)
pbinom(12,20,0.9)
pbinom(12,20,1)
pnorm(0.05)
qnorm(0.05)
1.644854*(sqrt(5/20))
pnorm(7.5,7,sqrt(5))
pnorm(7.5,7,sqrt(5/20))
pnorm(7.5,7.82,sqrt(5/20))
pnorm(8,7.82,sqrt(5/20))
pnorm(8.5,7.82,sqrt(5/20))
pnorm(9,7.82,sqrt(5/20))
qnorm(0.05)
qnorm(0.8)
pnorm(8,7.82,sqrt(5/20))
pnorm(8,7.82,sqrt(5/30))
pnorm(8,7.82,sqrt(5/50))
pnorm(8,7.82,sqrt(5/70))
pnorm(8,7.82,sqrt(5/80))
pnorm(8,7.82,sqrt(5/90))
pnorm(8,7.82,sqrt(5/100))
pnorm(8,7.82,sqrt(5/125))
pnorm(8,7.82,sqrt(5/120))
pnorm(8,7.82,sqrt(5/110))
pnorm(8,7.82,sqrt(5/100))
pnorm(8,7,sqrt(5/31))
# Set up a sequence of theta values between 0 and 1
theta <- seq(0, 1, length.out = 500)
# Compute the density of the Beta(6, 4) distribution
prior_density <- dbeta(theta, shape1 = 6, shape2 = 4)
# Plot the prior density
plot(theta, prior_density, type = "l", lwd = 2, col = "blue",
main = "Prior Density: Beta(6, 4)",
xlab = expression(theta),
ylab = expression(f(theta)),
ylim = c(0, max(prior_density) * 1.1))
grid()
qbeta(0.025,alpha=83,beta=27)
qbeta(0.025,83,27)
qbeta(0.5,83,27)
qbeta(0.025,83,27)
qbeta(0.975,83,27)
# Posterior parameters
alpha_post <- 83
beta_post <- 27
# Bayes estimate (posterior mean)
theta_hat <- alpha_post / (alpha_post + beta_post)
# 95% credible interval
ci <- qbeta(c(0.025, 0.975), alpha_post, beta_post)
# Theta values and density
theta_vals <- seq(0, 1, length.out = 1000)
posterior_density <- dbeta(theta_vals, alpha_post, beta_post)
# Plot the posterior density
plot(theta_vals, posterior_density, type = "l", lwd = 2, col = "blue",
main = "Posterior Density: Beta(83, 27)",
xlab = expression(theta), ylab = expression(f(theta)))
# Shade the 95% credible interval
polygon(c(ci[1], theta_vals[theta_vals >= ci[1] & theta_vals <= ci[2]], ci[2]),
c(0, posterior_density[theta_vals >= ci[1] & theta_vals <= ci[2]], 0),
col = rgb(0.2, 0.6, 1, 0.3), border = NA)
# Add vertical line for posterior mean (Bayes estimate)
abline(v = theta_hat, col = "red", lwd = 2, lty = 2)
# Add vertical lines for credible interval bounds
abline(v = ci, col = "darkgreen", lty = 3, lwd = 2)
# Add a legend
legend("topright", legend = c("Posterior Mean", "95% Credible Interval"),
col = c("red", "darkgreen"), lty = c(2, 3), lwd = 2, bty = "n")
# Prior parameters
mu_0 <- 15
sigma_0 <- 2.5
# Range of mu values
mu_vals <- seq(10, 20, length.out = 500)
# Compute the prior density
prior_density <- dnorm(mu_vals, mean = mu_0, sd = sigma_0)
# Plot
plot(mu_vals, prior_density, type = "l", lwd = 2, col = "blue",
main = expression(paste("Prior Density of ", mu, " ~ N(15, 2.5"^2, ")")),
xlab = expression(mu), ylab = expression(f(mu)))
grid()
qnorm(0.99)
qnorm(0.975)
qt(0.05,39)
qnorm(0.05)
library(titymodels)
library(tidymodels)
install.packages("tidymodels")
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
library(tidymodels)
library(tidyverse)
library(tidymodels)
library(tidymodels)
train <- vroom("train.csv")
library(vroom)
train <- vroom("train.csv")
test <- vroom("test.csv")
library(tidymodels)
library(tidymodels)
library(tidyverse)
library(vroom)
library(glmnet)
library(lubridate)
# Load CSV
train <- vroom("train.csv")
setwd("~/Documents/BYU Fall Semester 2025/STAT 348/Competitions/BikeShare")
library(tidymodels)
library(tidyverse)
library(vroom)
library(glmnet)
library(lubridate)
# Load CSV
train <- vroom("train.csv")
test  <- vroom("test.csv")
# Remove casual/registered
train <- train %>%
select(-any_of(c("registered", "casual")))
# Recipe
bike_recipe <- recipe(count ~ ., data = train) %>%
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>%
step_time(datetime, features = "hour") %>%
step_mutate(
hour_sin = sin(2 * pi * datetime_hour / 24),
hour_cos = cos(2 * pi * datetime_hour / 24)
) %>%
step_date(datetime, features = "dow") %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_rm(datetime)
# Define model
my_mod <- rand_forest(mtry = tune(), min_n = tune(), trees = 500) %>%
set_engine("ranger") %>%
set_mode("regression")
# Workflow
tree_wf <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(my_mod)
# Grid
tree_grid <- grid_regular(
mtry(range = c(1, 17)),
min_n(),
levels = 5
)
# CV folds
folds <- vfold_cv(train, v = 10)
# Tune
tree_results <- tree_wf %>%
tune_grid(
resamples = folds,
grid = tree_grid,
metrics = metric_set(rmse, mae)
)
best_tree <- tree_results %>% select_best(metric = "rmse")
final_tree_wf <- tree_wf %>% finalize_workflow(best_tree) %>% fit(train)
tree_preds <- predict(final_tree_wf, new_data = test)
# Kaggle submission
tree_submission <- tree_preds %>%
bind_cols(test) %>%
select(datetime, .pred) %>%
rename(count = .pred) %>%
mutate(count = pmax(0, count),
datetime = as.character(format(datetime)))
vroom_write(tree_submission, "./TreePreds.csv", delim = ",")
install.packages("bonsai")
install.packages("lightgbm")
library(tidymodels)
library(tidyverse)
library(vroom)
library(glmnet)
library(lubridate)
library(bonsai)
library(lightgbm)
# Load CSV
train <- vroom("train.csv")
test  <- vroom("test.csv")
# Remove casual/registered
train <- train %>%
select(-any_of(c("registered", "casual")))
# Recipe
bike_recipe <- recipe(count ~ ., data = train) %>%
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>%
step_time(datetime, features = "hour") %>%
step_mutate(
hour_sin = sin(2 * pi * datetime_hour / 24),
hour_cos = cos(2 * pi * datetime_hour / 24)
) %>%
step_date(datetime, features = "dow") %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_rm(datetime)
# Define model
bart_model <- bart(trees=tune()) %>%
set_engine("dbarts") %>%
set_mode("regression")
# Workflow
tree_wf <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(bart_model)
# Grid
tree_grid <- grid_regular(
mtry(range = c(1, 17)),
min_n(),
levels = 5
)
# CV folds
folds <- vfold_cv(train, v = 10)
# Tune
tree_results <- tree_wf %>%
tune_grid(
resamples = folds,
grid = tree_grid,
metrics = metric_set(rmse, mae)
)
install.packages("dbarts")
library(tidymodels)
library(tidyverse)
library(vroom)
library(glmnet)
library(lubridate)
library(bonsai)
library(lightgbm)
# Load CSV
train <- vroom("train.csv")
test  <- vroom("test.csv")
# Remove casual/registered
train <- train %>%
select(-any_of(c("registered", "casual")))
# Recipe
bike_recipe <- recipe(count ~ ., data = train) %>%
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>%
step_time(datetime, features = "hour") %>%
step_mutate(
hour_sin = sin(2 * pi * datetime_hour / 24),
hour_cos = cos(2 * pi * datetime_hour / 24)
) %>%
step_date(datetime, features = "dow") %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_rm(datetime)
# Define model
bart_model <- bart(trees=tune()) %>%
set_engine("dbarts") %>%
set_mode("regression")
# Workflow
tree_wf <- workflow() %>%
add_recipe(bike_recipe) %>%
add_model(bart_model)
# Grid
tree_grid <- grid_regular(
mtry(range = c(1, 17)),
min_n(),
levels = 5
)
# CV folds
folds <- vfold_cv(train, v = 10)
# Tune
tree_results <- tree_wf %>%
tune_grid(
resamples = folds,
grid = tree_grid,
metrics = metric_set(rmse, mae)
)
